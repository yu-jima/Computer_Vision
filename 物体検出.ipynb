{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-vision-computervision in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: msrest>=0.5.0 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from azure-cognitiveservices-vision-computervision) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from azure-cognitiveservices-vision-computervision) (1.1.28)\n",
      "Requirement already satisfied: azure-core>=1.24.0 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.28.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2023.5.7)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
      "Requirement already satisfied: requests~=2.16 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.0.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.2)\n",
      "Requirement already satisfied: pillow in /Users/yuiijima/.pyenv/versions/3.9.13/lib/python3.9/site-packages (9.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade azure-cognitiveservices-vision-computervision\n",
    "!pip3 install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secret.json') as f:\n",
    "    secret = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = secret['KEY']\n",
    "ENDPOINT = secret['ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'an ancient city with many ruins with Colosseum in the background' with confidence 33.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an image - remote =====\")\n",
    "description_results = computervision_client.describe_image(remote_image_url)\n",
    "\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Categorize an image - remote =====\n",
      "Categories from remote image: \n",
      "'building_' with confidence 31.64%\n",
      "'others_' with confidence 0.39%\n",
      "'outdoor_' with confidence 3.91%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Categorize an image - remote =====\")\n",
    "remote_image_features = [\"categories\"]\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an image - remote =====\")\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detecting objects in remote image:\n",
      "object at location 213, 365, 85, 208\n",
      "object at location 218, 402, 179, 384\n",
      "object at location 238, 417, 298, 416\n",
      "object at location 116, 419, 60, 386\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Detect Objects - remote =====\")\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - local =====\n",
      "Detecting objects in local image:\n",
      "object at location 879, 1201, 262, 773\n",
      "object at location 426, 1085, 835, 1271\n"
     ]
    }
   ],
   "source": [
    "local_image_path = 'sample01.jpg'\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "\n",
    "print(\"Detecting objects in local image:\")\n",
    "if len(detect_objects_results.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    tags_result = computervision_client.tag_image_in_stream(local_image)\n",
    "    tags = tags_result.tags\n",
    "    tags_name = []\n",
    "    for tag in tags:\n",
    "        tags_name.append(tag.name)\n",
    "\n",
    "    return tags_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tableware',\n",
       " 'food',\n",
       " 'baked goods',\n",
       " 'plate',\n",
       " 'drink',\n",
       " 'coffee cup',\n",
       " 'dishware',\n",
       " 'saucer',\n",
       " 'snack',\n",
       " 'serveware',\n",
       " 'meal',\n",
       " 'mug',\n",
       " 'tea',\n",
       " 'fast food',\n",
       " 'breakfast',\n",
       " 'fork',\n",
       " 'kitchen utensil',\n",
       " 'dish',\n",
       " 'brunch',\n",
       " 'platter',\n",
       " 'dessert',\n",
       " 'cup',\n",
       " 'coffee',\n",
       " 'indoor',\n",
       " 'sitting',\n",
       " 'table']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'sample01.jpg'\n",
    "get_tags(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "    objects = detect_objects_results.objects\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'sample01.jpg'\n",
    "objects = detect_objects(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[0].rectangle.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
